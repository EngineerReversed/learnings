{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Built-In sequences\n",
    "Python has 5 built-in sequence types:\n",
    "* Strings : *Immutable*\n",
    "* Tuples : *Immutable*\n",
    "* Lists : *Mutable*\n",
    "* Byte arrays : *Mutable*\n",
    "* Bytes : *Immutable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "<type 'str'>\n",
      "<type 'tuple'>\n",
      "<type 'bytearray'>\n",
      "<type 'str'>\n"
     ]
    }
   ],
   "source": [
    "# python in built sequence datatypes\n",
    "l = []\n",
    "s = ''\n",
    "t = ()\n",
    "ba = bytearray(b'')\n",
    "b = bytes([])\n",
    "print(type(l))\n",
    "print(type(s))\n",
    "print(type(t))\n",
    "print(type(ba))\n",
    "print(type(b))    # only for python 3.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set(['people', 'dingdong', 'tomey'])\n",
      "set(['tomey', 'dingdong', 'people'])\n",
      "set(['people', 'dingdong', 'tomey'])\n",
      "set(['people', 'tomey'])\n",
      "set(['dingdong'])\n",
      "set(['people', 'tomey'])\n"
     ]
    }
   ],
   "source": [
    "# Immutable objects in python\n",
    "# there are collection data types (sets and dictionaries) which are accessed via immutables datatypes\n",
    "# Concept of deep copying!\n",
    "myList = {'people','tomey','dingdong'}\n",
    "slayers = myList.copy()    # it creates a new copy\n",
    "slayers1 = myList    # it creates a new reference\n",
    "print(myList)\n",
    "print(slayers)\n",
    "print(slayers1)\n",
    "slayers.discard('people')\n",
    "slayers.remove('tomey')\n",
    "slayers1.discard('dingdong')\n",
    "print(myList)\n",
    "print(slayers)\n",
    "print(slayers1)\n",
    "\n",
    "import copy\n",
    "m = copy.copy(slayers)\n",
    "n = copy.deepcopy(slayers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Strings\n",
    "Every python object has two output forms :\n",
    "* String form - readable by humans\n",
    "* Representational form -  readable by python interpretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yo Bro !\n"
     ]
    }
   ],
   "source": [
    "# Unicode strings\n",
    "# here space is represented by u0020 Unicode - 16 bits\n",
    "# ASCII code takes 8 bits to represent\n",
    "\n",
    "print(u'Yo\\u0020Bro !')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abhishek Karunesh Arpit\n",
      "Abhishek-<>-Karunesh-<>-Arpit\n",
      "Arpit__|__Karunesh__|__Abhishek\n"
     ]
    }
   ],
   "source": [
    "# Methods for strings\n",
    "# using join is better than using + to concatenate a list\n",
    "list_of_names = ['Abhishek','Karunesh','Arpit']\n",
    "print(' '.join(list_of_names))    # join method\n",
    "print('-<>-'.join(list_of_names))\n",
    "print('__|__'.join(reversed(list_of_names)))    # reverse method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------Abhishek Shakya\n",
      "Abhishek Shakya-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# rjust and ljust methods\n",
    "name = 'Abhishek Shakya'\n",
    "print(name.rjust(50,'-'))    # adding at the end\n",
    "print(name.ljust(50,'-'))    # adding at the start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am the one, No I am not!\n",
      "Number 999 is a good abhishek\n"
     ]
    }
   ],
   "source": [
    "# format method\n",
    "# strings can be formatted\n",
    "print('{0}, {1}').format('I am the one','No I am not!')\n",
    "\n",
    "# string mapping or unmapping\n",
    "# the idea is to combine local() method with format resulting in a key-value list suitable for passing to a function\n",
    "number = 999\n",
    "string = 'abhishek'\n",
    "print('Number {number} is a good {string}'.format(**locals()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abhishek shakya', 'ding dong', 'hello hello', 'somebody in there']\n",
      "['abhishek shakya', 'ding dong', 'hello hello\\nsomebody in there']\n",
      "['abhishek', 'shakya\\nding', 'dong\\nhello', 'hello\\nsomebody', 'in', 'there']\n",
      "['abhishek', 'shakya\\nding', 'dong\\nhello', 'hello\\nsomebody', 'in', 'there']\n"
     ]
    }
   ],
   "source": [
    "# splitlines function in python\n",
    "random_string = 'abhishek shakya\\nding dong\\nhello hello\\nsomebody in there'\n",
    "print(random_string.splitlines())\n",
    "\n",
    "# using split\n",
    "print(random_string.split('\\n',2))    #    split occured only 2 times\n",
    "print(random_string.split(' '))\n",
    "print(random_string.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Abhishek' 'shakya']\n",
      " ['pulkit' 'shakya']]\n"
     ]
    }
   ],
   "source": [
    "# it requires a special condition that number of words or separable entitites should be same\n",
    "with open('random_text.txt','r') as txt:\n",
    "    text = np.genfromtxt(txt,dtype ='string')    # this is good for reading data in columnar structure like logs\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abhishek shakya\\nding dong\\nhello hello\\nsomebody', 'in', 'there']\n"
     ]
    }
   ],
   "source": [
    "# using rsplit function\n",
    "print(random_string.rsplit(' ',2))    # splitting from right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "abhishek\n",
      "shakya\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'abhishek\\nshakya'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the strip chars method\n",
    "sample_string = '\\nabhishek\\nshakya\\n'\n",
    "print(sample_string)\n",
    "sample_string.strip('\\n')    # removes the trailing spaces from end or front\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Problem Statement\\n', 'Welcome to Gardenia - A country which believes in creating a harmony between technology and natural resources. Over the years, Gardenia has come up with ways to utilise natural resources effectively and they have enabled this with use of cutting edge technology.\\n', '\\xc2\\xa0\\n', 'The country takes pride in the way it has maintained its natural resources and Gardens. Now, the government of Gardenia wants to use data science to understand the health habits of their citizens. So, they started to capture several variables from various parks in the country.\\n', '\\xc2\\xa0\\n', 'They now have this data over a long period of time and are looking for experts like yourself to look at the data and tell, if you can predict how many people will come to a park on a particular day, given the environmental information.\\n', '\\xc2\\xa0\\n', 'Go, help the mayor of Gardenia! He has high hopes from Analytics Vidhya community! All the best!\\n', '\\n']\n"
     ]
    }
   ],
   "source": [
    "# reading text file\n",
    "with open('sample_text.txt','r') as text_object:\n",
    "    text = text_object.readlines()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'all', 'help', 'over', 'its', 'information.', 'to', 'health', 'has', 'resources', 'resources.', 'government', 'gardens.', 'cutting', 'they', 'now', 'like', 'technology.', 'best!', 'country.', 'habits', 'people', 'analytics', 'are', 'for', 'ways', 'mayor', 'looking', 'day,', 'years,', 'between', 'various', 'creating', 'of', 'given', 'come', 'on', 'country', 'community!', 'variables', 'period', 'yourself', 'maintained', 'now,', 'use', 'from', 'takes', 'long', 'their', 'way', 'wants', 'statement', 'go,', 'started', 'park', 'so,', 'citizens.', 'environmental', 'understand', 'particular', 'hopes', 'with', 'he', 'pride', '\\xc2\\xa0', 'look', 'this', 'science', 'enabled', 'up', 'believes', 'will', 'can', 'many', 'problem', 'and', 'vidhya', 'predict', 'it', 'high', 'effectively', 'experts', 'at', 'have', 'in', 'technology', 'if', 'capture', 'gardenia!', '-', 'parks', 'how', 'harmony', 'which', 'you', 'several', 'tell,', 'utilise', 'gardenia', 'welcome', 'data', 'a', 'natural', 'edge', 'time', 'the']\n",
      "('', '-->', 1)\n",
      "('-', '-->', 1)\n",
      "('a', '-->', 5)\n",
      "('all', '-->', 1)\n",
      "('analytics', '-->', 1)\n",
      "('and', '-->', 5)\n",
      "('are', '-->', 1)\n",
      "('at', '-->', 1)\n",
      "('believes', '-->', 1)\n",
      "('best!', '-->', 1)\n",
      "('between', '-->', 1)\n",
      "('can', '-->', 1)\n",
      "('capture', '-->', 1)\n",
      "('citizens.', '-->', 1)\n",
      "('come', '-->', 2)\n",
      "('community!', '-->', 1)\n",
      "('country', '-->', 2)\n",
      "('country.', '-->', 1)\n",
      "('creating', '-->', 1)\n",
      "('cutting', '-->', 1)\n",
      "('data', '-->', 3)\n",
      "('day,', '-->', 1)\n",
      "('edge', '-->', 1)\n",
      "('effectively', '-->', 1)\n",
      "('enabled', '-->', 1)\n",
      "('environmental', '-->', 1)\n",
      "('experts', '-->', 1)\n",
      "('for', '-->', 1)\n",
      "('from', '-->', 2)\n",
      "('gardenia', '-->', 3)\n",
      "('gardenia!', '-->', 1)\n",
      "('gardens.', '-->', 1)\n",
      "('given', '-->', 1)\n",
      "('go,', '-->', 1)\n",
      "('government', '-->', 1)\n",
      "('habits', '-->', 1)\n",
      "('harmony', '-->', 1)\n",
      "('has', '-->', 3)\n",
      "('have', '-->', 2)\n",
      "('he', '-->', 1)\n",
      "('health', '-->', 1)\n",
      "('help', '-->', 1)\n",
      "('high', '-->', 1)\n",
      "('hopes', '-->', 1)\n",
      "('how', '-->', 1)\n",
      "('if', '-->', 1)\n",
      "('in', '-->', 3)\n",
      "('information.', '-->', 1)\n",
      "('it', '-->', 1)\n",
      "('its', '-->', 1)\n",
      "('like', '-->', 1)\n",
      "('long', '-->', 1)\n",
      "('look', '-->', 1)\n",
      "('looking', '-->', 1)\n",
      "('maintained', '-->', 1)\n",
      "('many', '-->', 1)\n",
      "('mayor', '-->', 1)\n",
      "('natural', '-->', 3)\n",
      "('now', '-->', 1)\n",
      "('now,', '-->', 1)\n",
      "('of', '-->', 5)\n",
      "('on', '-->', 1)\n",
      "('over', '-->', 2)\n",
      "('park', '-->', 1)\n",
      "('parks', '-->', 1)\n",
      "('particular', '-->', 1)\n",
      "('people', '-->', 1)\n",
      "('period', '-->', 1)\n",
      "('predict', '-->', 1)\n",
      "('pride', '-->', 1)\n",
      "('problem', '-->', 1)\n",
      "('resources', '-->', 2)\n",
      "('resources.', '-->', 1)\n",
      "('science', '-->', 1)\n",
      "('several', '-->', 1)\n",
      "('so,', '-->', 1)\n",
      "('started', '-->', 1)\n",
      "('statement', '-->', 1)\n",
      "('takes', '-->', 1)\n",
      "('technology', '-->', 1)\n",
      "('technology.', '-->', 1)\n",
      "('tell,', '-->', 1)\n",
      "('the', '-->', 10)\n",
      "('their', '-->', 1)\n",
      "('they', '-->', 3)\n",
      "('this', '-->', 2)\n",
      "('time', '-->', 1)\n",
      "('to', '-->', 7)\n",
      "('understand', '-->', 1)\n",
      "('up', '-->', 1)\n",
      "('use', '-->', 2)\n",
      "('utilise', '-->', 1)\n",
      "('variables', '-->', 1)\n",
      "('various', '-->', 1)\n",
      "('vidhya', '-->', 1)\n",
      "('wants', '-->', 1)\n",
      "('way', '-->', 1)\n",
      "('ways', '-->', 1)\n",
      "('welcome', '-->', 1)\n",
      "('which', '-->', 1)\n",
      "('will', '-->', 1)\n",
      "('with', '-->', 2)\n",
      "('years,', '-->', 1)\n",
      "('you', '-->', 1)\n",
      "('yourself', '-->', 1)\n",
      "('\\xc2\\xa0', '-->', 3)\n"
     ]
    }
   ],
   "source": [
    "# creating a tf-idf document using strip() function\n",
    "import string\n",
    "import sys\n",
    "word_dict = {}\n",
    "def count_unique_word(text):\n",
    "    for line in text:\n",
    "        words = line.lower().strip('\\n').split(' ')\n",
    "        for word in words:\n",
    "            if word not in word_dict:\n",
    "                word_dict[word] = 1\n",
    "            else:\n",
    "                word_dict[word] +=1\n",
    "    print(list(word_dict))    # printing every key(word) of dictionary \n",
    "    # sorted(word_dict) will give keys sorted in ascending order\n",
    "    for word in sorted(word_dict):\n",
    "        print(word,'-->',word_dict[word])\n",
    "\n",
    "if __name__=='__main__':\n",
    "    count_unique_word(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the: 10\n",
      "to: 7\n",
      "of: 5\n",
      "and: 5\n",
      "a: 5\n",
      "has: 3\n",
      "they: 3\n",
      " : 3\n",
      "in: 3\n",
      "gardenia: 3\n",
      "data: 3\n",
      "natural: 3\n",
      "over: 2\n",
      "resources: 2\n",
      "come: 2\n",
      "country: 2\n",
      "use: 2\n",
      "from: 2\n",
      "with: 2\n",
      "this: 2\n",
      "have: 2\n",
      ": 1\n",
      "all: 1\n",
      "help: 1\n",
      "its: 1\n",
      "information.: 1\n",
      "health: 1\n",
      "resources.: 1\n",
      "government: 1\n",
      "gardens.: 1\n",
      "cutting: 1\n",
      "now: 1\n",
      "like: 1\n",
      "technology.: 1\n",
      "best!: 1\n",
      "country.: 1\n",
      "habits: 1\n",
      "people: 1\n",
      "analytics: 1\n",
      "are: 1\n",
      "for: 1\n",
      "ways: 1\n",
      "mayor: 1\n",
      "looking: 1\n",
      "day,: 1\n",
      "years,: 1\n",
      "between: 1\n",
      "various: 1\n",
      "creating: 1\n",
      "given: 1\n",
      "on: 1\n",
      "community!: 1\n",
      "variables: 1\n",
      "period: 1\n",
      "yourself: 1\n",
      "maintained: 1\n",
      "now,: 1\n",
      "takes: 1\n",
      "long: 1\n",
      "their: 1\n",
      "way: 1\n",
      "wants: 1\n",
      "statement: 1\n",
      "go,: 1\n",
      "started: 1\n",
      "park: 1\n",
      "so,: 1\n",
      "citizens.: 1\n",
      "environmental: 1\n",
      "understand: 1\n",
      "particular: 1\n",
      "hopes: 1\n",
      "he: 1\n",
      "pride: 1\n",
      "look: 1\n",
      "science: 1\n",
      "enabled: 1\n",
      "up: 1\n",
      "believes: 1\n",
      "will: 1\n",
      "can: 1\n",
      "many: 1\n",
      "problem: 1\n",
      "vidhya: 1\n",
      "predict: 1\n",
      "it: 1\n",
      "high: 1\n",
      "effectively: 1\n",
      "experts: 1\n",
      "at: 1\n",
      "technology: 1\n",
      "if: 1\n",
      "capture: 1\n",
      "gardenia!: 1\n",
      "-: 1\n",
      "parks: 1\n",
      "how: 1\n",
      "harmony: 1\n",
      "which: 1\n",
      "you: 1\n",
      "several: 1\n",
      "tell,: 1\n",
      "utilise: 1\n",
      "welcome: 1\n",
      "edge: 1\n",
      "time: 1\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "sorted_word = sorted(word_dict.items(),key = operator.itemgetter(1), reverse = True)\n",
    "for tup in sorted_word:\n",
    "    print('{}: {}'.format(tup[0],tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# earlier we found spaces and some punctuation marks interfering our counting process\n",
    "# so we would use some advanced techniques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
